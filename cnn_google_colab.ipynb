{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQ2TwcqVdlNpWpL9tVxzj2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigobivarazevedo/machine_learning/blob/main/cnn_google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pm2FXJTG0om-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b67870-7bf5-4d1f-9902-ed9cec98f2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx8BZsZC10TV",
        "outputId": "dd569851-62ae-4f84-df8a-77448915f684"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "4.140263399999981\n",
            "GPU (s):\n",
            "0.11985618400001385\n",
            "GPU speedup over CPU: 34x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we using a GPU? If not: go to Runtime -> Change runtime type -> Hardware accelerator: GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLgta8fP2CWz",
        "outputId": "e22e74ff-70ae-46b4-cc67-6a6cdd2f77f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 30 11:44:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             25W /   70W |    1206MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Funtions"
      ],
      "metadata": {
        "id": "M__tbhCx3fuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Data"
      ],
      "metadata": {
        "id": "IgQAzm2f3iiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomHeight, RandomWidth\n",
        "import numpy as np\n",
        "\n",
        "def data_augmentation_object():\n",
        "    return keras.Sequential([\n",
        "        RandomFlip(\"horizontal\"),\n",
        "        RandomRotation(0.2),\n",
        "        RandomZoom(0.2),\n",
        "        RandomHeight(0.2),\n",
        "        RandomWidth(0.2),\n",
        "    ], name=\"data_augmentation\")\n",
        "\n",
        "def print_class_distribution(dataset, dataset_name):\n",
        "    class_counts = dataset.classes\n",
        "    class_indices = dataset.class_indices\n",
        "    unique_classes, counts = np.unique(class_counts, return_counts=True)\n",
        "    print(f\"Class distribution for {dataset_name}:\")\n",
        "    for class_idx, count in zip(unique_classes, counts):\n",
        "        print(f\"  Class {class_idx}: {count} samples\")\n",
        "    print(f\"  Class indices: {class_indices}\")\n",
        "    print(f\"  Class distribution (as percentages):\")\n",
        "    for class_idx, count in zip(unique_classes, counts):\n",
        "        percentage = (count / len(class_counts)) * 100\n",
        "        print(f\"    Class {class_idx}: {percentage:.2f}%\")\n",
        "    print(\"-\")\n",
        "\n",
        "\n",
        "def data_preprocessing(train_dataset_path=\"dataset_dogs_vs_cats/train\",\n",
        "                       test_dataset_path=\"dataset_dogs_vs_cats/test\",\n",
        "                       img_size=(128, 128),\n",
        "                       batch_size=32,\n",
        "                       class_mode=\"binary\"):\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_data = train_datagen.flow_from_directory(\n",
        "        train_dataset_path,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        subset=\"training\"\n",
        "    )\n",
        "\n",
        "    val_data = train_datagen.flow_from_directory(\n",
        "        train_dataset_path,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        subset=\"validation\"\n",
        "    )\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_data = test_datagen.flow_from_directory(\n",
        "        test_dataset_path,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    print_class_distribution(train_data, \"Training Set\")\n",
        "    print_class_distribution(val_data, \"Validation Set\")\n",
        "    print_class_distribution(test_data, \"Test Set\")\n",
        "\n",
        "    return train_data, val_data, test_data, data_augmentation_object()\n"
      ],
      "metadata": {
        "id": "LvfbEH-j3e9Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare Image and Predict"
      ],
      "metadata": {
        "id": "8aoaBJWM3q0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (img_shape, img_shape, 3)\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img_array = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img_array = tf.image.resize(img, [img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  if scale:\n",
        "    return img_array/255.\n",
        "  else:\n",
        "    return img_array, img\n",
        "\n",
        "# Function to predict a single image\n",
        "def predict_image(img_path, model, img_size=(128, 128)):\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(\"Test image not found!\")\n",
        "        return\n",
        "\n",
        "    img_array, img = load_and_prep_image(img_path, img_shape=img_size[0], scale=True) # load and preprocess the image\n",
        "\n",
        "    # Expand the dimensions of the image array to match the input shape of the model\n",
        "    img_expanded = tf.expand_dims(img_array, axis=0) # expand image dimensions (224, 224, 2) -> (1, 224, 224, 3) if img_shape = 224 and binary classification\n",
        "    #img_expanded = np.expand_dims(img_array, axis=0) # expand image dimensions (224, 224, 2) -> (1, 224, 224, 3) if img_shape = 224 and binary classification\n",
        "\n",
        "    # Make a prediction\n",
        "    prediction = model.predict(img_expanded)\n",
        "    result = \"Dog\" if prediction[0][0] > 0.5 else \"Cat\"\n",
        "    confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]\n",
        "\n",
        "    print(f\"Prediction: {result} with {confidence:.2%} confidence\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{result}, prob: {confidence:.2%}\")\n",
        "    plt.axis(False);\n",
        "\n",
        "    return result, confidence\n",
        "\n",
        "\n",
        "def pred_and_plot(model, image, class_names):\n",
        "  pred_probs = model.predict(tf.expand_dims(image, axis=0))\n",
        "  pred_class = class_names[tf.argmax(pred_probs[0])]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(f\"{pred_class}, prob: {tf.reduce_max(pred_probs):.2f}\")\n",
        "  plt.axis(False);\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_yjrN3_g3lDy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Training Function"
      ],
      "metadata": {
        "id": "myXqkbtR4TsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "def train_model(model, train_data, val_data, epochs=10):\n",
        "    \"\"\"\n",
        "    Trains the model using the provided training and validation data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define callbacks for better training\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    learning_rate_reduction = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        patience=2,\n",
        "        factor=0.5,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        validation_data=val_data,\n",
        "        epochs=epochs,\n",
        "        callbacks=[early_stopping, learning_rate_reduction]\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "siBV4fRG3x3d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate Model Functions"
      ],
      "metadata": {
        "id": "T0Z957H24X7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_train_validation_history(history):\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "def get_model_metrics(model, test_data):\n",
        "\n",
        "    # Get true labels and predictions\n",
        "    y_true = test_data.classes  # True labels from test set\n",
        "    y_pred_probs = model.predict(test_data)  # Probabilities\n",
        "\n",
        "    # check if model is binary or categorical\n",
        "    if len(model.output_shape) == 2:\n",
        "        y_pred = (y_pred_probs > 0.5).astype(int).flatten()  # Convert probabilities to binary labels\n",
        "\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Print classification report (includes precision, recall, F1-score)\n",
        "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=['Cat', 'Dog']))\n",
        "\n",
        "    # Compute precision and recall\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "OOajJ56B3x0o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Efficient Net Model"
      ],
      "metadata": {
        "id": "64czcuQR4ek2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Real-time Augmentation During Training\n",
        "On-the-fly augmentation: Each time an image is passed through the model during training, the augmentation will be applied. This means your model sees different versions of the same image during each epoch, helping it generalize better.\n",
        "Efficiency: This method allows augmentation to be part of the model graph, enabling efficient GPU computation and possibly reducing memory usage since augmented images aren't saved on disk but created in memory during training.\n",
        "2. Applied Only to the Training Data\n",
        "No augmentation for validation and test data: The augmentation layer will be applied only during training, so the validation and test datasets remain unchanged (no augmentation). This ensures that model evaluation is based on the original data, providing an accurate assessment of its performance."
      ],
      "metadata": {
        "id": "-Lb8m28k4gcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a function to build a model\n",
        "def create_EfficientNet_model(data_augmentation,\n",
        "                              input_shape=(224, 224, 3),\n",
        "                              base_model=tf.keras.applications.EfficientNetB0(include_top=False),\n",
        "                              num_classes=2):\n",
        "  # Fine-tune?\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Add in data augmentation Sequential model as a layer\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  # Give base_model inputs (after augmentation) and don't train it\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  # Pool output features of base model\n",
        "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "\n",
        "  if num_classes > 2:\n",
        "    # Put a dense layer on as the output for multi-class classification\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "    # Add a dropout layer for regularization and to prevent overfitting\n",
        "    #x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Make a model with inputs and outputs\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model for multi-class classification\n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                    optimizer=tf.keras.optimizers.Adam(),\n",
        "                    metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  else:\n",
        "    # Put a dense layer on as the output for binary classification\n",
        "    outputs = layers.Dense(num_classes, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "\n",
        "    #x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # Make a model with inputs and outputs\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Compile the model for binary classification\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(),\n",
        "                 metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "XajFrM3f4mdr",
        "outputId": "28e93d6e-b2ce-4c9a-d39a-7d46a00c20d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Binary CNN model"
      ],
      "metadata": {
        "id": "AulyOHZ94q29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "\n",
        "def create_binary_cnn_model(data_augmentation, input_shape=(128, 128, 3)):\n",
        "\n",
        "    # Define CNN model\n",
        "    model = Sequential([\n",
        "        # Apply Augmentation as a Preprocessing Layer in the Model\n",
        "        data_augmentation,\n",
        "\n",
        "        # First convolutional block\n",
        "        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        # Second convolutional block\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        # Third convolutional block\n",
        "        Conv2D(128, (3,3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "        # Fully connected layers\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model for binary classification\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer='adam',\n",
        "                 metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "2l6g2Dny4nW1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 - larger images"
      ],
      "metadata": {
        "id": "leUMv4Ri4vbj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSRY-_fp4sTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3 - MobileNet ransfer learning"
      ],
      "metadata": {
        "id": "XnNRlTcQ4zxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetV2 is a convolutional neural network architecture designed for mobile and edge devices. It was introduced by Google researchers in 2018 as an improvement over the original MobileNet architecture.\n",
        "Key characteristics of MobileNetV2:\n",
        "\n",
        "Efficiency: It's specifically designed to be lightweight and computationally efficient, making it suitable for mobile devices, embedded systems, and edge computing.\n",
        "Architecture Features:\n",
        "\n",
        "Uses depthwise separable convolutions (which split standard convolutions into depthwise and pointwise convolutions)\n",
        "Introduces an inverted residual structure where the residual connections are between the bottleneck layers\n",
        "Implements linear bottlenecks between layers to prevent information loss\n",
        "\n",
        "\n",
        "Performance: Despite being lightweight, it achieves good accuracy on image classification tasks. It strikes an excellent balance between model size, speed, and accuracy.\n",
        "Pre-trained Weights: It comes with pre-trained weights on the ImageNet dataset, which makes it excellent for transfer learning (where you take a pre-trained model and fine-tune it for your specific task).\n",
        "Use Cases: Common applications include image classification, object detection, and segmentation on resource-constrained devices."
      ],
      "metadata": {
        "id": "_kqxXnp142eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create MobileNet Model"
      ],
      "metadata": {
        "id": "EZETfeS846Bx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Transfer learning with MobileNetV2\n",
        "def create_transfer_learning_model(data_augmentation, img_size=(128, 128)):\n",
        "\n",
        "    # Load the pretrained model\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(*img_size, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze the base model (no fine-tuning)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Create new model on top\n",
        "    model = Sequential([\n",
        "        data_augmentation,\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile model with a lower learning rate\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    # Model summary\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "90tE0Kf740OG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_transfer_learning_model()  # Option 2: Transfer learning (better performance)\n",
        "\n",
        "# Define callbacks for better training\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    factor=0.5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stopping, learning_rate_reduction]\n",
        ")\n",
        "\n",
        "test_results = model.evaluate(test_data, verbose=1)\n",
        "print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
        "print(f\"Test Precision: {test_results[2]:.4f}\")\n",
        "print(f\"Test Recall: {test_results[3]:.4f}\")\n",
        "print(f\"Test F1-Score: {2 * (test_results[2] * test_results[3]) / (test_results[2] + test_results[3]):.4f}\")"
      ],
      "metadata": {
        "id": "1efZI5y35C8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 4 - more layers"
      ],
      "metadata": {
        "id": "C76OSDno5GXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Advanced CNN model from scratch\n",
        "def create_custom_model(data_augmentation, img_size=(224, 224)):\n",
        "    model = Sequential([\n",
        "\n",
        "        # Apply augmentation before passing to the base model\n",
        "        data_augmentation,\n",
        "\n",
        "        # First convolutional block\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(*img_size, 3)),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Second convolutional block\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Third convolutional block\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Fourth convolutional block\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        # Fully connected layers\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "A4Evs_Dx47h8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_glLKYoW5IhP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}